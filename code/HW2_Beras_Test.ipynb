{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS1470/2470 HW2: Testing Notebook\n",
    "\n",
    "\n",
    "We love unit tests.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the scale of this assignment, we've included a notebook for unit testing the individual \n",
    "components that you will code. Feel free to edit this notebook however you want (e.g. adding print\n",
    "statements for shapes and stuff). Please note that there might be slight differences between the \n",
    "expected output and your outputs in terms of the shapes and values due to broadcasting and floating \n",
    "point values; use your best judgement if differences do appear and if you still aren't sure, \n",
    "feel free to post on Ed!\n",
    "\n",
    "A lot of the functions you will write influence the outputs of each other, making it really \n",
    "frustrating sometimes to debug. Hopefully these tests will help you pinpoint where exactly your \n",
    "model is correct/incorrect and thus will lead to a lot less hair pulling! :D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 20:33:30.776891: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport Beras, assignment\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense Input:\n",
      "[[-5 -4 -3 -2 -1  0  1  2  3  4]]\n",
      "\n",
      "Dense Output:\n",
      "[[0. 0. 0. 0. 0.]]\n",
      "\n",
      "Weight Gradients:\n",
      "[Tensor([[[-5., -5., -5., -5., -5.],\n",
      "         [-4., -4., -4., -4., -4.],\n",
      "         [-3., -3., -3., -3., -3.],\n",
      "         [-2., -2., -2., -2., -2.],\n",
      "         [-1., -1., -1., -1., -1.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.],\n",
      "         [ 1.,  1.,  1.,  1.,  1.],\n",
      "         [ 2.,  2.,  2.,  2.,  2.],\n",
      "         [ 3.,  3.,  3.,  3.,  3.],\n",
      "         [ 4.,  4.,  4.,  4.,  4.]]]), Tensor([[1., 1., 1., 1., 1.]])]\n",
      "\n",
      "Weight Gradient Shapes:\n",
      "(1, 10, 5)\n",
      "(1, 5)\n",
      "\n",
      "Input Gradients:\n",
      "[Tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])]\n",
      "\n",
      "Input Gradient Shapes:\n",
      "(10, 5)\n"
     ]
    }
   ],
   "source": [
    "from Beras.layers import Dense\n",
    "\n",
    "\n",
    "# Define inputs for testing\n",
    "in_size, out_size = 10, 5\n",
    "inputs = np.arange(-5,5).reshape((1, in_size))\n",
    "\n",
    "# Define implementation\n",
    "student_implementation = Dense(in_size, out_size, initializer=\"zero\")\n",
    "outputs = student_implementation(inputs)\n",
    "\n",
    "print(\"Dense Input:\")\n",
    "print(inputs)\n",
    "print(\"\\nDense Output:\")\n",
    "print(outputs)\n",
    "print(\"\\nWeight Gradients:\")\n",
    "print(student_implementation.weight_gradients())\n",
    "print(\"\\nWeight Gradient Shapes:\")\n",
    "print(student_implementation.weight_gradients()[0].shape)\n",
    "print(student_implementation.weight_gradients()[1].shape)\n",
    "print(\"\\nInput Gradients:\")\n",
    "print(student_implementation.input_gradients())\n",
    "print(\"\\nInput Gradient Shapes:\")\n",
    "print(student_implementation.input_gradients()[0].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**> Expected Output** (Double Click)\n",
    "<!--\n",
    "```\n",
    "Dense Input:\n",
    "[[-5 -4 -3 -2 -1  0  1  2  3  4]]\n",
    "\n",
    "Dense Output:\n",
    "[[0. 0. 0. 0. 0.]]\n",
    "\n",
    "Weight Gradients:\n",
    "[Variable([[[-5., -5., -5., -5., -5.],\n",
    "           [-4., -4., -4., -4., -4.],\n",
    "           [-3., -3., -3., -3., -3.],\n",
    "           [-2., -2., -2., -2., -2.],\n",
    "           [-1., -1., -1., -1., -1.],\n",
    "           [ 0.,  0.,  0.,  0.,  0.],\n",
    "           [ 1.,  1.,  1.,  1.,  1.],\n",
    "           [ 2.,  2.,  2.,  2.,  2.],\n",
    "           [ 3.,  3.,  3.,  3.,  3.],\n",
    "           [ 4.,  4.,  4.,  4.,  4.]]]), Variable([[1., 1., 1., 1., 1.]])]\n",
    "\n",
    "Weight Gradient Shapes:\n",
    "(1, 10, 5)\n",
    "(1, 5)\n",
    "\n",
    "Input Gradients:\n",
    "[Variable([[0., 0., 0., 0., 0.],\n",
    "          [0., 0., 0., 0., 0.],\n",
    "          [0., 0., 0., 0., 0.],\n",
    "          [0., 0., 0., 0., 0.],\n",
    "          [0., 0., 0., 0., 0.],\n",
    "          [0., 0., 0., 0., 0.],\n",
    "          [0., 0., 0., 0., 0.],\n",
    "          [0., 0., 0., 0., 0.],\n",
    "          [0., 0., 0., 0., 0.],\n",
    "          [0., 0., 0., 0., 0.]])]\n",
    "\n",
    "Input Gradient Shapes:\n",
    "(10, 5)\n",
    "```-->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "Predictions\n",
      "[[0.1, 0.9, 0.8], [0.05, 0.95, 0]]\n",
      "Labels\n",
      "[[0, 0, 1], [0, 1, 0]]\n",
      "\n",
      "Outputs:\n",
      "Student Implementation\n",
      "0.5\n",
      "Keras Implementation\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 10:16:41.174069: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from Beras.metrics import CategoricalAccuracy\n",
    "\n",
    "# Define inputs for testing\n",
    "y_pred = [[0.1, 0.9, 0.8], [0.05, 0.95, 0]]\n",
    "y_true = [[0, 0, 1], [0, 1, 0]]\n",
    "\n",
    "# Define implementations for comparison\n",
    "student_implementation = CategoricalAccuracy() \n",
    "keras_implementation = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "print(\"Inputs:\")\n",
    "\n",
    "print(\"Predictions\")\n",
    "print(y_pred)\n",
    "\n",
    "print(\"Labels\")\n",
    "print(y_true)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Outputs:\")\n",
    "print(\"Student Implementation\")\n",
    "print(student_implementation(y_true, y_pred))\n",
    "print(\"Keras Implementation\")\n",
    "print(keras_implementation(y_true, y_pred).numpy())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Input:\n",
      "[[[-12. -11. -10.  -9.]\n",
      "  [ -8.  -7.  -6.  -5.]\n",
      "  [ -4.  -3.  -2.  -1.]]\n",
      "\n",
      " [[  0.   1.   2.   3.]\n",
      "  [  4.   5.   6.   7.]\n",
      "  [  8.   9.  10.  11.]]]\n",
      "\n",
      "Activation Output:\n",
      "[[[-3.6 -3.3 -3.  -2.7]\n",
      "  [-2.4 -2.1 -1.8 -1.5]\n",
      "  [-1.2 -0.9 -0.6 -0.3]]\n",
      "\n",
      " [[ 0.   1.   2.   3. ]\n",
      "  [ 4.   5.   6.   7. ]\n",
      "  [ 8.   9.  10.  11. ]]]\n",
      "Shape of (2, 3, 4)\n",
      "\n",
      "Input Gradients:\n",
      "[[[[0.3 0.3 0.3 0.3]\n",
      "   [0.3 0.3 0.3 0.3]\n",
      "   [0.3 0.3 0.3 0.3]]\n",
      "\n",
      "  [[0.  1.  1.  1. ]\n",
      "   [1.  1.  1.  1. ]\n",
      "   [1.  1.  1.  1. ]]]]\n",
      "\n",
      "Input Gradient Shapes:\n",
      "(1, 2, 3, 4)\n",
      "\n",
      "Compose to Input:\n",
      "[[[-1.08 -0.99 -0.9  -0.81]\n",
      "  [-0.72 -0.63 -0.54 -0.45]\n",
      "  [-0.36 -0.27 -0.18 -0.09]]\n",
      "\n",
      " [[ 0.    1.    2.    3.  ]\n",
      "  [ 4.    5.    6.    7.  ]\n",
      "  [ 8.    9.   10.   11.  ]]]\n",
      "\n",
      "Compose to Input Shapes:\n",
      "(2, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "from Beras.activations import LeakyReLU\n",
    "\n",
    "# Define inputs for testing (batchsize of 2, each a 3 x 4 array)\n",
    "inputs = np.float64(np.arange(-12, 12).reshape(2, 3, 4))\n",
    "\n",
    "# Define implementation\n",
    "student_implementation = LeakyReLU()\n",
    "outputs = student_implementation(inputs)\n",
    "\n",
    "print(\"Activation Input:\")\n",
    "print(inputs)\n",
    "print(\"\\nActivation Output:\")\n",
    "print(outputs)\n",
    "print(f\"Shape of {outputs.shape}\")\n",
    "print(\"\\nInput Gradients:\")\n",
    "print(np.array(student_implementation.input_gradients()))\n",
    "print(\"\\nInput Gradient Shapes:\")\n",
    "print(np.array(student_implementation.input_gradients()).shape)\n",
    "print(\"\\nCompose to Input:\")\n",
    "print(student_implementation.compose_to_input(outputs))\n",
    "print(\"\\nCompose to Input Shapes:\")\n",
    "print(np.array(student_implementation.compose_to_input(outputs)).shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**> Expected Output**\n",
    "<!--\n",
    "```\n",
    "Activation Input:\n",
    "[[[-12. -11. -10.  -9.]\n",
    "  [ -8.  -7.  -6.  -5.]\n",
    "  [ -4.  -3.  -2.  -1.]]\n",
    "\n",
    " [[  0.   1.   2.   3.]\n",
    "  [  4.   5.   6.   7.]\n",
    "  [  8.   9.  10.  11.]]]\n",
    "\n",
    "Activation Output:\n",
    "[[[-3.6 -3.3 -3.  -2.7]\n",
    "  [-2.4 -2.1 -1.8 -1.5]\n",
    "  [-1.2 -0.9 -0.6 -0.3]]\n",
    "\n",
    " [[ 0.   1.   2.   3. ]\n",
    "  [ 4.   5.   6.   7. ]\n",
    "  [ 8.   9.  10.  11. ]]]\n",
    "Shape of (2, 3, 4)\n",
    "\n",
    "Input Gradients:\n",
    "[[[[0.3 0.3 0.3 0.3]\n",
    "   [0.3 0.3 0.3 0.3]\n",
    "   [0.3 0.3 0.3 0.3]]\n",
    "\n",
    "  [[0.  1.  1.  1. ]\n",
    "   [1.  1.  1.  1. ]\n",
    "   [1.  1.  1.  1. ]]]]\n",
    "\n",
    "Input Gradient Shapes:\n",
    "(1, 2, 3, 4)\n",
    "\n",
    "Compose to Input:\n",
    "[[[-1.08 -0.99 -0.9  -0.81]\n",
    "  [-0.72 -0.63 -0.54 -0.45]\n",
    "  [-0.36 -0.27 -0.18 -0.09]]\n",
    "\n",
    " [[ 0.    1.    2.    3.  ]\n",
    "  [ 4.    5.    6.    7.  ]\n",
    "  [ 8.    9.   10.   11.  ]]]\n",
    "\n",
    "Compose to Input Shapes:\n",
    "(2, 3, 4)\n",
    "```-->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax (2470 Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "[[-8. -7. -6. -5.]\n",
      " [-4. -3. -2. -1.]\n",
      " [ 0.  1.  2.  3.]\n",
      " [ 4.  5.  6.  7.]]\n",
      "\n",
      "Activation Outputs:\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mActivation Outputs:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInput Gradients:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(student_implementation\u001b[38;5;241m.\u001b[39minput_gradients()))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from Beras.activations import Softmax\n",
    "\n",
    "# Define inputs for testing (batchsize of 4 with 4 elements each)\n",
    "inputs = np.float64(np.arange(-8, 8).reshape(4, 4))\n",
    "\n",
    "# Define implementation\n",
    "student_implementation = Softmax()\n",
    "outputs = student_implementation(inputs)\n",
    "\n",
    "print(\"Input:\")\n",
    "print(inputs)\n",
    "print(\"\\nActivation Outputs:\")\n",
    "print(outputs)\n",
    "print(f\"Shape of {outputs.shape}\")\n",
    "print(\"\\nInput Gradients:\")\n",
    "print(np.array(student_implementation.input_gradients()))\n",
    "print(\"\\nInput Gradient Shapes:\")\n",
    "print(np.array(student_implementation.input_gradients()).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**> Expected Output**\n",
    "<!--\n",
    "```\n",
    "Input:\n",
    "[[-8. -7. -6. -5.]\n",
    " [-4. -3. -2. -1.]\n",
    " [ 0.  1.  2.  3.]\n",
    " [ 4.  5.  6.  7.]]\n",
    "\n",
    "Activation Outputs:\n",
    "[[0.0320586  0.08714432 0.23688282 0.64391426]\n",
    " [0.0320586  0.08714432 0.23688282 0.64391426]\n",
    " [0.0320586  0.08714432 0.23688282 0.64391426]\n",
    " [0.0320586  0.08714432 0.23688282 0.64391426]]\n",
    "Shape of (4, 4)\n",
    "\n",
    "Input Gradients:\n",
    "[[[[ 0.03103085 -0.00279373 -0.00759413 -0.02064299]\n",
    "   [-0.00279373  0.07955019 -0.02064299 -0.05611347]\n",
    "   [-0.00759413 -0.02064299  0.18076935 -0.15253222]\n",
    "   [-0.02064299 -0.05611347 -0.15253222  0.22928869]]\n",
    "\n",
    "  [[ 0.03103085 -0.00279373 -0.00759413 -0.02064299]\n",
    "   [-0.00279373  0.07955019 -0.02064299 -0.05611347]\n",
    "   [-0.00759413 -0.02064299  0.18076935 -0.15253222]\n",
    "   [-0.02064299 -0.05611347 -0.15253222  0.22928869]]\n",
    "\n",
    "  [[ 0.03103085 -0.00279373 -0.00759413 -0.02064299]\n",
    "   [-0.00279373  0.07955019 -0.02064299 -0.05611347]\n",
    "   [-0.00759413 -0.02064299  0.18076935 -0.15253222]\n",
    "   [-0.02064299 -0.05611347 -0.15253222  0.22928869]]\n",
    "\n",
    "  [[ 0.03103085 -0.00279373 -0.00759413 -0.02064299]\n",
    "   [-0.00279373  0.07955019 -0.02064299 -0.05611347]\n",
    "   [-0.00759413 -0.02064299  0.18076935 -0.15253222]\n",
    "   [-0.02064299 -0.05611347 -0.15253222  0.22928869]]]]\n",
    "\n",
    "Input Gradient Shapes:\n",
    "(1, 4, 4, 4)\n",
    "   ```-->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BasicOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "Weights: [-1.  1.]\n",
      "Grads: [ 0.5 -0.5]\n",
      "\n",
      "Outputs t=1:\n",
      "Weights: [-1.025  1.025]\n",
      "\n",
      "Outputs t=2:\n",
      "Weights: [-1.05  1.05]\n"
     ]
    }
   ],
   "source": [
    "from Beras.optimizers import BasicOptimizer\n",
    "from Beras import Tensor\n",
    "\n",
    "# Define inputs\n",
    "learning_rate = 0.05\n",
    "\n",
    "weights = Tensor([-1., 1.])\n",
    "grads = Tensor([0.5, -0.5])\n",
    "\n",
    "# Define implementation\n",
    "student_implementation = BasicOptimizer(learning_rate)\n",
    "\n",
    "print(\"Inputs:\")\n",
    "print(f\"Weights: {weights}\")\n",
    "print(f\"Grads: {grads}\")\n",
    "print(\"\\nOutputs t=1:\")\n",
    "student_implementation.apply_gradients([weights], [grads])\n",
    "print(f\"Weights: {weights}\")\n",
    "print(\"\\nOutputs t=2:\")\n",
    "student_implementation.apply_gradients([weights], [grads])\n",
    "print(f\"Weights: {weights}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**> Expected Output**\n",
    "<!--\n",
    "```\n",
    "Inputs:\n",
    "Weights: [-1.  1.]\n",
    "Grads: [ 0.5 -0.5]\n",
    "\n",
    "Outputs t=1:\n",
    "Weights: [-1.025  1.025]\n",
    "\n",
    "Outputs t=2:\n",
    "Weights: [-1.05  1.05]\n",
    "```-->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "Weights: [-1.  1.]\n",
      "Grads: [ 0.5 -0.5]\n",
      "\n",
      "Outputs t=1:\n",
      "Weights: [-1.11180335  1.11180335]\n",
      "Running Average: [(0, Tensor([0.05, 0.05]))]\n",
      "\n",
      "Outputs t=2:\n",
      "Weights: [-1.19513665  1.19513665]\n",
      "Running Average: [(0, Tensor([0.09, 0.09]))]\n"
     ]
    }
   ],
   "source": [
    "from Beras.optimizers import RMSProp\n",
    "\n",
    "# Define inputs\n",
    "learning_rate = 0.05\n",
    "beta = 0.8\n",
    "epsilon = 1e-7\n",
    "\n",
    "weights = Tensor([-1., 1.])\n",
    "grads   = Tensor([0.5, -0.5])\n",
    "\n",
    "# Define implementation\n",
    "student_implementation = RMSProp(learning_rate, beta=beta, epsilon=epsilon)\n",
    "\n",
    "print(\"Inputs:\")\n",
    "print(f\"Weights: {weights}\")\n",
    "print(f\"Grads: {grads}\")\n",
    "print(\"\\nOutputs t=1:\")\n",
    "student_implementation.apply_gradients([weights], [grads])\n",
    "print(f\"Weights: {weights}\")\n",
    "print(f\"Running Average: {list(student_implementation.v.items())}\")\n",
    "print(\"\\nOutputs t=2:\")\n",
    "student_implementation.apply_gradients([weights], [grads])\n",
    "print(f\"Weights: {weights}\")\n",
    "print(f\"Running Average: {list(student_implementation.v.items())}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**> Expected Output**\n",
    "<!--\n",
    "```\n",
    "Inputs:\n",
    "Weights: [-1.  1.]\n",
    "Grads: [ 0.5 -0.5]\n",
    "\n",
    "Outputs t=1:\n",
    "Weights: [-1.11180335  1.11180335]\n",
    "Running Average: [(0, Tensor([0.05, 0.05]))]\n",
    "\n",
    "Outputs t=2:\n",
    "Weights: [-1.19513665  1.19513665]\n",
    "Running Average: [(0, Tensor([0.09, 0.09]))]\n",
    "```-->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "Weights: [Tensor([-1.,  1.])]\n",
      "Grads: [Tensor([ 0.5, -0.5])]\n",
      "\n",
      "Outputs t=1:\n",
      "Weights: [Tensor([-1.0499999,  1.0499999])]\n",
      "First moment: [(0, Tensor([ 0.1, -0.1]))]\n",
      "Second moment: [(0, Tensor([0.028, 0.028]))]\n",
      "Expected first moment: [(0, Tensor([ 0.5, -0.5]))]\n",
      "Expected second moment: [(0, Tensor([0.25, 0.25]))]\n",
      "\n",
      "Outputs t=2:\n",
      "Weights: [Tensor([-1.0999998,  1.0999998])]\n",
      "First moment: [(0, Tensor([ 0.18, -0.18]))]\n",
      "Second moment: [(0, Tensor([0.052864, 0.052864]))]\n",
      "Expected first moment: [(0, Tensor([ 0.5, -0.5]))]\n",
      "Expected second moment: [(0, Tensor([0.25, 0.25]))]\n"
     ]
    }
   ],
   "source": [
    "from Beras.optimizers import Adam\n",
    "\n",
    "# Define inputs\n",
    "learning_rate = 0.05\n",
    "beta_1 = 0.8\n",
    "beta_2 = 0.888\n",
    "epsilon = 1e-6\n",
    "\n",
    "weights = [Tensor([-1., 1.])]\n",
    "grads = [Tensor([0.5, -0.5])]\n",
    "\n",
    "# Define implementation\n",
    "student_implementation = Adam(learning_rate, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon, amsgrad=False)\n",
    "\n",
    "print(\"Inputs:\")\n",
    "print(f\"Weights: {weights}\")\n",
    "print(f\"Grads: {grads}\")\n",
    "print(\"\\nOutputs t=1:\")\n",
    "student_implementation.apply_gradients(weights, grads)\n",
    "print(f\"Weights: {weights}\")\n",
    "print(f\"First moment: {list(student_implementation.m.items())}\")\n",
    "print(f\"Second moment: {list(student_implementation.v.items())}\")\n",
    "print(f\"Expected first moment: {list(student_implementation.m_hat.items())}\")\n",
    "print(f\"Expected second moment: {list(student_implementation.v_hat.items())}\")\n",
    "print(\"\\nOutputs t=2:\")\n",
    "student_implementation.apply_gradients(weights, grads)\n",
    "print(f\"Weights: {weights}\")\n",
    "print(f\"First moment: {list(student_implementation.m.items())}\")\n",
    "print(f\"Second moment: {list(student_implementation.v.items())}\")\n",
    "print(f\"Expected first moment: {list(student_implementation.m_hat.items())}\")\n",
    "print(f\"Expected second moment: {list(student_implementation.v_hat.items())}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**> Expected Output**\n",
    "<!--\n",
    "```\n",
    "Inputs:\n",
    "Weights: [Tensor([-1.,  1.])]\n",
    "Grads: [Tensor([ 0.5, -0.5])]\n",
    "\n",
    "Outputs t=1:\n",
    "Weights: [Tensor([-1.0499999,  1.0499999])]\n",
    "First moment: [(0, Tensor([ 0.1, -0.1]))]\n",
    "Second moment: [(0, Tensor([0.028, 0.028]))]\n",
    "Expected first moment: [(0, Tensor([ 0.5, -0.5]))]\n",
    "Expected second moment: [(0, Tensor([0.25, 0.25]))]\n",
    "\n",
    "Outputs t=2:\n",
    "Weights: [Tensor([-1.0999998,  1.0999998])]\n",
    "First moment: [(0, Tensor([ 0.18, -0.18]))]\n",
    "Second moment: [(0, Tensor([0.052864, 0.052864]))]\n",
    "Expected first moment: [(0, Tensor([ 0.5, -0.5]))]\n",
    "Expected second moment: [(0, Tensor([0.25, 0.25]))]\n",
    "```-->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "759be6693a164ddeab1e231298c2a01a8302a7c7dfd4e560844dbce42a896f34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
